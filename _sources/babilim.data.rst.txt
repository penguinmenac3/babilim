Data
====

The data package is all about data handling.

**Dataset** is the most important class in the data package.
Every babilim project and even non babilim projects must/should have a Dataset-class.
This class defines an easy interface to your dataset.
You implement the `version`-property, `__len__(self)` and `getitem(self, index)` methods and the Dataset takes care of the rest.


.. code-block:: python

    import babilim
    from babilim.experiment import Config
    from babilim.data import Dataset, image_grid_wrap

    class MyFancyDataset(Dataset):
        def __init__(self, config: Config, phase: str):
            super().__init__(config)
            # TODO do some preprocessing of your dataset, e.g. figuring out what files you want to use
            # and defining what file gets opened by an index.
            self.filenames = []

        def __len__(self) -> int:
            return len(self.filenames)

        def getitem(self, idx: int) -> Tuple[NetworkInput, NetworkOutput]:
            # TODO load your image and class label for the training example with index idx.
            # (Note this is not a batch but a single example)
            return NetworkInput(features=image_grid_wrap(image)), NetworkOutput(class_id=label)

        @property
        def version(self) -> str:
            return "MyFancyDataset"

    # Create your training dataset
    dataset = MyFancyDataset(config, babilim.PHASE_TRAIN)

    # If you want to manually train your model, you can get a native dataset with batching in one line
    batched_tensor_dataset = dataset.to_native()


**Transformer** and a **TransformedDataset** can be used to apply minor transformations to your dataset.
A typical use-case would be applying an encoding required for a specific neural network (e.g. one hot encoding).
*It should not be used for complex transformations and any transformation that changes the length of your dataset, use a dataset wrapper for that.*

**image_grid_wrap** and **image_grid_unwrap** are functions which must be applied on any image input data for your network.
This ensures that the dimensions are correct for both pytorch and tensorflow since they both need different representations for image grid data.

A lot more features can be found in this package (like binary data loading helpers, MultiZipReaders to help reading from zipped datasets and more).

**Autogenerated Documentation**

.. automodule:: babilim.data
   :members:
   :undoc-members:
   :show-inheritance:

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# babilim.core.config\n",
    "\n",
    "> The base class for every config.\n",
    "\n",
    "This code is under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2019 Michael Fuerst\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import sys\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "import importlib\n",
    "import inspect\n",
    "\n",
    "_sentinel = object()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "## ConfigPart\n",
    "\n",
    "A partial config.\n",
    "Generally a config can consist of config parts or primitive types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConfigPart(object):\n",
    "    \"\"\"\n",
    "    Converts a dictionary into an object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Create an object from a dictionary.\n",
    "\n",
    "        :param d: The dictionary to convert.\n",
    "        \"\"\"\n",
    "        self.immutable = False\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def to_dict(self) -> Dict:\n",
    "        dictionary = dict((key, value.to_dict()) if isinstance(value, ConfigPart) else (key, value)\n",
    "                          for (key, value) in self.__dict__.items())\n",
    "        del dictionary[\"immutable\"]\n",
    "        return dictionary\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"ConfigPart(\" + self.__str__() + \")\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        out = \"\"\n",
    "        for k, v in sorted(self.to_dict().items(), key=lambda x: x[0]):\n",
    "            out += \"{}: {}\\n\".format(k, v)\n",
    "        return out\n",
    "\n",
    "    def get(self, key: str, default: Any = _sentinel) -> Any:\n",
    "        \"\"\"\n",
    "        Get the value specified in the dictionary or a default.\n",
    "        :param key: The key which should be retrieved.\n",
    "        :param default: The default that is returned if the key is not set.\n",
    "        :return: The value from the dict or the default.\n",
    "        \"\"\"\n",
    "        if default is _sentinel:\n",
    "            default = ConfigPart()\n",
    "        return self.__dict__[key] if key in self.__dict__ else default\n",
    "\n",
    "    def __getitem__(self, key: str) -> Any:\n",
    "        \"\"\"\n",
    "        Get the value specified in the dictionary or a dummy.\n",
    "        :param key: The key which should be retrieved.\n",
    "        :return: The value from the dict or a dummy.\n",
    "        \"\"\"\n",
    "        return self.get(key)\n",
    "\n",
    "    def __setattr__(self, key: str, value: Any) -> None:\n",
    "        if \"immutable\" not in self.__dict__:  # In case users might not call constructor\n",
    "            self.__dict__[\"immutable\"] = False\n",
    "        if self.immutable:\n",
    "            raise RuntimeError(\"Trying to modify hyperparameters outside constructor.\")\n",
    "\n",
    "        if isinstance(value, str):\n",
    "            # Try to match linux path style with anything that matches\n",
    "            for env_var in list(os.environ.keys()):\n",
    "                s = \"$\" + env_var\n",
    "                value = value.replace(s, os.environ[env_var].replace(\"\\\\\", \"/\"))\n",
    "\n",
    "            # Try to match windows path style with anything that matches\n",
    "            for env_var in list(os.environ.keys()):\n",
    "                s = \"%\" + env_var + \"%\"\n",
    "                value = value.replace(s, os.environ[env_var].replace(\"\\\\\", \"/\"))\n",
    "\n",
    "            if \"%\" in value or \"$\" in value:\n",
    "                raise RuntimeError(\"Cannot resove all environment variables used in: '{}'\".format(value))\n",
    "        super.__setattr__(self, key, value)\n",
    "\n",
    "    def __eq__(self, other: 'ConfigPart') -> bool:\n",
    "        if not isinstance(other, ConfigPart):\n",
    "            # don't attempt to compare against unrelated types\n",
    "            return NotImplemented\n",
    "\n",
    "        for k in self.__dict__:\n",
    "            if not k in other.__dict__:\n",
    "                return False\n",
    "            if not self.__dict__[k] == other.__dict__[k]:\n",
    "                return False\n",
    "\n",
    "        for k in other.__dict__:\n",
    "            if not k in self.__dict__:\n",
    "                return False\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#hide\n",
    "\n",
    "## Config\n",
    "\n",
    "Base config for all configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Config(ConfigPart):\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        A configuration for a deep learning project.\n",
    "\n",
    "        This class should never be instantiated directly, subclass it instead.\n",
    "\n",
    "        The following parameters are set by default and should be changed after calling super.\n",
    "        \n",
    "            train_batch_size = 1\n",
    "            train_experiment_name = None\n",
    "            train_checkpoint_path = \"checkpoints\"\n",
    "            train_epochs = 50\n",
    "            train_log_steps = 100\n",
    "            train_learning_rate_shedule = None\n",
    "            train_optimizer = None\n",
    "            arch_prepare = None\n",
    "            arch_model = None\n",
    "            arch_loss = None\n",
    "            arch_metrics = None\n",
    "            problem_base_dir = None\n",
    "            problem_dataset = None\n",
    "\n",
    "        You can add further attributes by simply adding them.\n",
    "        \"\"\"\n",
    "        # Training parameters.\n",
    "        self.train_batch_size = 1\n",
    "        self.train_experiment_name = None\n",
    "        self.train_checkpoint_path = \"checkpoints\"\n",
    "        self.train_epochs = 50\n",
    "        self.train_log_steps = 100\n",
    "\n",
    "        # Architectural parameters (like preparing the data, the model, the loss and then some metrics)\n",
    "        self.arch_prepare = None\n",
    "        self.arch_model = None\n",
    "        self.arch_loss = None\n",
    "        self.arch_metrics = None\n",
    "\n",
    "        # Required for general dataset loading. (Non architecture specific.)\n",
    "        self.problem_base_dir = None\n",
    "        self.problem_dataset = None\n",
    "        self.problem_shuffle = True\n",
    "        self.problem_num_threads = 0\n",
    "\n",
    "        # The following should not be changed, since babilim will change them internally.\n",
    "        self.train_actual_checkpoint_path = None\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \"Config(\" + self.__str__() + \")\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __has_attribute(obj: object, name: str) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the object has an attribute.\n",
    "\n",
    "        :param obj: The object that should be checked.\n",
    "        :param name: The attribute that should be found.\n",
    "        :return: True if the object has the attribute, False otherwise.\n",
    "        \"\"\"\n",
    "        return name in obj.__dict__ and obj.__dict__[name] is not None\n",
    "\n",
    "    def check_completness(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check the config for completeness.\n",
    "\n",
    "        This method checks for the common bare minimum.\n",
    "        If it fails to find something it throws an assertion error.\n",
    "        :return: True if no exception occurs.\n",
    "        \"\"\"\n",
    "        # Check for training parameters\n",
    "        assert Config.__has_attribute(self, \"train_experiment_name\")\n",
    "        assert Config.__has_attribute(self, \"train_checkpoint_path\")\n",
    "        assert Config.__has_attribute(self, \"train_batch_size\")\n",
    "        assert Config.__has_attribute(self, \"train_epochs\")\n",
    "        assert Config.__has_attribute(self, \"train_log_steps\")\n",
    "        assert Config.__has_attribute(self, \"problem_base_dir\")\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Configs\n",
    "\n",
    "For easily importing configs use the following two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def import_config(config_file: str) -> Any:\n",
    "    \"\"\"\n",
    "    Only libraries should use this method. Human users should directly import their configs.\n",
    "    Automatically imports the most specific config from a given file.\n",
    "\n",
    "    :param config_file: The configuration file which should be loaded.\n",
    "    :return: The configuration object.\n",
    "    \"\"\"\n",
    "    module_name = config_file.replace(\"\\\\\", \".\").replace(\"/\", \".\").replace(\".py\", \"\")\n",
    "    module = importlib.import_module(module_name)\n",
    "    module = importlib.reload(module)\n",
    "    symbols = list(module.__dict__.keys())\n",
    "    symbols = [x for x in symbols if not x.startswith(\"__\")]\n",
    "    n = None\n",
    "    for x in symbols:\n",
    "        if not inspect.isclass(module.__dict__[x]):  # in Case we found something that is not a class ignore it.\n",
    "            continue\n",
    "        if issubclass(module.__dict__[x], Config):\n",
    "            # Allow multiple derivatives of config, when they are derivable from each other in any direction.\n",
    "            if n is not None and not issubclass(module.__dict__[x], module.__dict__[n]) and not issubclass(\n",
    "                    module.__dict__[n], module.__dict__[x]):\n",
    "                raise RuntimeError(\n",
    "                    \"You must only have one class derived from Config in {}. It cannot be decided which to use.\".format(\n",
    "                        config_file))\n",
    "            # Pick the most specific one if they can be derived.\n",
    "            if n is None or issubclass(module.__dict__[x], module.__dict__[n]):\n",
    "                n = x\n",
    "    if n is None:\n",
    "        raise RuntimeError(\"There must be at least one class in {} derived from Config.\".format(config_file))\n",
    "    config = module.__dict__[n]()\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def import_checkpoint_config(config_file: str) -> Any:\n",
    "    \"\"\"\n",
    "    Adds the folder in which the config_file is to the pythonpath, imports it and removes the folder from the python path again.\n",
    "\n",
    "    :param config_file: The configuration file which should be loaded.\n",
    "    :return: The configuration object.\n",
    "    \"\"\"\n",
    "    config_file = config_file.replace(\"\\\\\", \"/\")\n",
    "    config_folder = \"/\".join(config_file.split(\"/\")[:-2])\n",
    "    config_file_name=\"/\".join(config_file.split(\"/\")[-2:])\n",
    "\n",
    "    sys.path.append(config_folder)\n",
    "    config = import_config(config_file_name)\n",
    "    sys.path.remove(config_folder)\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

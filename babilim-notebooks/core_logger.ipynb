{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# babilim.core.logger\n",
    "\n",
    "> Logging for tensorflow and pytorch.\n",
    "\n",
    "This code is under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2019 Michael Fuerst\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import datetime\n",
    "import filecmp\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from typing import Callable, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from babilim.core.config import Config\n",
    "from babilim import info, warn, DEBUG_VERBOSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "__log_file = None\n",
    "__checkpoint_path = None\n",
    "__last_progress = 0\n",
    "__last_update = time.time()\n",
    "\n",
    "PYTHON_IGNORE_LIST = [\"__pycache__\", \"*.pyc\", \".ipynb_checkpoints\", \"checkpoints\", \"dist\", \"docs\", \"*.egg-info\",\n",
    "                      \"tfrecords\", \"*.code-workspace\", \".git\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _format_time(t):\n",
    "    hours, remainder = divmod(t, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return '%d:%02d:%02d' % (hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _ignore(candidate: str, forbidden_list: List[str]) -> bool:\n",
    "    # Parse list to find simple placeholder notations\n",
    "    start_list = []\n",
    "    end_list = []\n",
    "    for item in forbidden_list:\n",
    "        if item.startswith(\"*\"):\n",
    "            end_list.append(item.replace(\"*\", \"\"))\n",
    "        if item.endswith(\"*\"):\n",
    "            start_list.append(item.replace(\"*\", \"\"))\n",
    "    # Test\n",
    "    res = candidate in forbidden_list\n",
    "    for item in start_list:\n",
    "        res |= candidate.startswith(item)\n",
    "    for item in end_list:\n",
    "        res |= candidate.endswith(item)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def __get_all_files(root: str, forbidden_list: List[str]) -> List[str]:\n",
    "    all_files = []\n",
    "    root_with_sep = root + os.sep\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        files = [x for x in files if not _ignore(x, forbidden_list)]\n",
    "        subdirs[:] = [x for x in subdirs if not x.startswith(\".\") and not _ignore(x, forbidden_list)]\n",
    "        for name in files:\n",
    "            all_files.append(os.path.join(path, name).replace(root_with_sep, \"\"))\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_loaded_files(root: str = None, forbidden_list: List[str] = PYTHON_IGNORE_LIST) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of all files that correspond to loaded modules in the root folder.\n",
    "\n",
    "    If root is None the current cwd is used.\n",
    "    \"\"\"\n",
    "    if root is None:\n",
    "        root = os.getcwd()\n",
    "\n",
    "    cwd_files = __get_all_files(root, forbidden_list)\n",
    "    # TODO filter out all files that are not loaded.\n",
    "\n",
    "    return cwd_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_backup_path(fname: str, outp_dir: str = None) -> str:\n",
    "    assert outp_dir is not None\n",
    "\n",
    "    return os.path.join(os.path.normpath(outp_dir), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _copyfile(src: str, dst: str, follow_symlinks: bool = True, create_missing_dirs: bool = True) -> None:\n",
    "    dst_dir = os.path.dirname(dst)\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "\n",
    "    shutil.copyfile(src, dst, follow_symlinks=follow_symlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _write_log(*, obj: object) -> None:\n",
    "    \"\"\"\n",
    "    Write a log to the logfile or console if none is available.\n",
    "    Furthermore send it to the online server if it is connected.\n",
    "\n",
    "    :param obj: The json serializable object to log.\n",
    "    \"\"\"\n",
    "    global __log_file\n",
    "    out_str = json.dumps(obj)\n",
    "    if __log_file is None:\n",
    "        warn(\"You should setup logger before using it. Call ailab.logger.setup(...).\")\n",
    "        warn(out_str)\n",
    "    else:\n",
    "        with open(__log_file, \"a\") as f:\n",
    "            f.write(out_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def log_value(*, name: str, value: object) -> None:\n",
    "    \"\"\"\n",
    "    Log a value to the file or online server.\n",
    "    :param name: The name of the value to be logged.\n",
    "    :param value: The actual value. It can be anything that is json serializable.\n",
    "    \"\"\"\n",
    "    date = {\n",
    "        \"timestamp\": \"{}\".format(datetime.datetime.now()),\n",
    "        \"name\": name,\n",
    "        \"value\": value\n",
    "    }\n",
    "    _write_log(obj=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def log_progress(goal: str, progress: float, score: float) -> None:\n",
    "    \"\"\"\n",
    "    Update the progress value. Automatically also computes the ETA and updates it in the logs.\n",
    "    :param goal: The current goal it tries to reach. (\"training\", \"validating\", \"pause\", \"waiting\", \"done\")\n",
    "    :param progress: A value between 0 and 1 indicating the progress, where 1 means done. The value should grow monotonic.\n",
    "    :param score: The score that the approach achieved.\n",
    "    \"\"\"\n",
    "    global __last_progress\n",
    "    global __last_update\n",
    "\n",
    "    assert 0 <= progress <= 1, progress\n",
    "\n",
    "    delta_t = time.time() - __last_update\n",
    "    delta_p = max(progress - __last_progress, 1E-6)\n",
    "    __last_update = time.time()\n",
    "    __last_progress = progress\n",
    "    eta = (1.0 - progress) / delta_p * delta_t\n",
    "    if goal == \"pause\" or goal == \"waiting\":\n",
    "        eta = 0\n",
    "\n",
    "    date = {\n",
    "        \"timestamp\": \"{}\".format(datetime.datetime.now()),\n",
    "        \"eta\": _format_time(eta),\n",
    "        \"goal\": str(goal),\n",
    "        \"score\": int(score * 1000) / 1000,\n",
    "        \"progress\": int(progress * 1000) / 1000\n",
    "    }\n",
    "    _write_log(obj=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _log_code(*, chkpt_path: str, forbidden_list: list = []) -> None:\n",
    "    \"\"\"\n",
    "    Log the code of the current working directory into the src folder of your checkpoint path.\n",
    "\n",
    "    :param chkpt_path: The checkpoint folder.\n",
    "    :param forbidden_list: The list of the forbidden files.\n",
    "    \"\"\"\n",
    "    outp_dir = os.path.join(chkpt_path, \"src\")\n",
    "    forbidden_list.extend(PYTHON_IGNORE_LIST)\n",
    "\n",
    "    loaded_files = _get_loaded_files(forbidden_list=forbidden_list)\n",
    "    # Copy preparation code to output location and load the module.\n",
    "    for f in loaded_files:\n",
    "        f_backup = _get_backup_path(f, outp_dir=outp_dir)\n",
    "        _copyfile(f, f_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _is_code_log_up_to_date(*, chkpt_path: str, forbidden_list: list = []) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the code in the logs is up to date or needs updates.\n",
    "\n",
    "    :param chkpt_path: The checkpoint folder.\n",
    "    :param forbidden_list: The list of the forbidden files.\n",
    "    :return: True if the files are up to date, False if not.\n",
    "    \"\"\"\n",
    "    outp_dir = os.path.join(chkpt_path, \"src\")\n",
    "    if not os.path.exists(outp_dir):\n",
    "        return False\n",
    "    forbidden_list.extend(PYTHON_IGNORE_LIST)\n",
    "    loaded_files = _get_loaded_files(forbidden_list=forbidden_list)\n",
    "\n",
    "    for f in loaded_files:\n",
    "        f_backup = _get_backup_path(f, outp_dir=outp_dir)\n",
    "        # Check if data is already up to date\n",
    "        if not os.path.exists(f_backup) or not filecmp.cmp(f, f_backup):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def log_image(*, name: str, data: np.ndarray = None) -> None:\n",
    "    \"\"\"\n",
    "    Log an image.\n",
    "    :param name: The name of the image.\n",
    "    :param data: The data (optional) if none is provided it is assumed that a pyplot figure should be saved.\n",
    "    \"\"\"\n",
    "    global __checkpoint_path\n",
    "    if __checkpoint_path is None:\n",
    "        warn(\"Cannot log images when logger is not setup. Call logger.setup first\")\n",
    "        return\n",
    "    if data is None:\n",
    "        plt.savefig(os.path.join(__checkpoint_path, \"images\", name + \".png\"))\n",
    "    else:\n",
    "        scipy.misc.imsave(os.path.join(__checkpoint_path, \"images\", name + \".png\"), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def close(reason: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Close the logger for a given reason.\n",
    "    \n",
    "    If none is provided there is no final progress written. Provide a reason, if you do not manually set the final progress before.\n",
    "    A training loop typically manually sets the progress, so you will not need a reason in that case.\n",
    "    \n",
    "    :param reason: The reason for the closing of the logger. It is recommended to use \"done\", \"paused\", \"failed\" as reason.\n",
    "    \"\"\"\n",
    "    global __log_file\n",
    "    global __checkpoint_path\n",
    "    global __last_progress\n",
    "    global __last_update\n",
    "    if __log_file is None:\n",
    "        raise RuntimeError(\"You must setup the logger before you can close it!\")\n",
    "    if reason is not None:\n",
    "        log_progress(goal=reason, progress=1.0, score=0.0)\n",
    "\n",
    "    __log_file = None\n",
    "    __checkpoint_path = None\n",
    "    __last_progress = 0\n",
    "    __last_update = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setup_minimal(log_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Setup the a simple logger (not suitable for training) but for data generation/preprocessing.\n",
    "    \n",
    "    Creates the log folder, a src folder inside the log folder where it copies the current working directory and creates a log.txt, for logging progress.\n",
    "\n",
    "    :param log_folder: Folder where the logs should be created.\n",
    "    \"\"\"\n",
    "    global __log_file\n",
    "    if __log_file is not None:\n",
    "        raise RuntimeError(\"You must not setup logger twice!\")\n",
    "    if not os.path.exists(log_folder):\n",
    "        os.makedirs(log_folder)\n",
    "\n",
    "    if not _is_code_log_up_to_date(chkpt_path=log_folder):\n",
    "        _log_code(chkpt_path=log_folder)\n",
    "    __log_file = os.path.join(log_folder, \"log.txt\")\n",
    "    log_progress(goal=\"waiting\", progress=0, score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setup(config: Config, continue_with_specific_checkpointpath: bool = False, continue_training: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Setup the logger.\n",
    "    This creates the folder structure required at the place specified in config.train.checkpoint_path.\n",
    "    After creating the folder structure it backs up the code of the current working directory to the folder structure.\n",
    "\n",
    "    :param config: The configuration that is used for this run.\n",
    "    :param continue_with_specific_checkpointpath: When a specific checkpoint is used to continue a run, set this. This avoids creating a new folder if it is not required.\n",
    "    :param continue_training: Same as specific checkpoint but the checkpoint is automatically selected to be the most recent. This avoids creating a new folder if it is not required.\n",
    "    :return: The path to the checkpoint folder.\n",
    "    \"\"\"\n",
    "    global __log_file\n",
    "    global __checkpoint_path\n",
    "    if __log_file is not None:\n",
    "        raise RuntimeError(\"You must not setup logger twice!\")\n",
    "    time_stamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H.%M.%S')\n",
    "    chkpt_path = config.train_checkpoint_path + \"/\" + time_stamp\n",
    "    chkpt_path = chkpt_path + \"_\" + config.train_experiment_name\n",
    "\n",
    "    if continue_with_specific_checkpointpath:\n",
    "        chkpt_path = config.train_checkpoint_path + \"/\" + continue_with_specific_checkpointpath\n",
    "        if DEBUG_VERBOSITY:\n",
    "            info(\"Continue with checkpoint: {}\".format(chkpt_path))\n",
    "    elif continue_training:\n",
    "        chkpts = sorted([name for name in os.listdir(config.train_checkpoint_path)])\n",
    "        chkpt_path = config.train_checkpoint_path + \"/\" + chkpts[-1]\n",
    "        if DEBUG_VERBOSITY:\n",
    "            info(\"Latest found checkpoint: {}\".format(chkpt_path))\n",
    "\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"train\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"train\"))\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"val\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"val\"))\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"checkpoints\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"checkpoints\"))\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"images\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"images\"))\n",
    "\n",
    "    setup_minimal(log_folder=chkpt_path)\n",
    "    __checkpoint_path = chkpt_path\n",
    "    config.train_actual_checkpoint_path = chkpt_path\n",
    "    return chkpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LogResult(object):\n",
    "    def __init__(self, *, name: str) -> None:\n",
    "        \"\"\"\n",
    "        Annotation to log the result of a function.\n",
    "\n",
    "        A simple example would be the primary loss the training pipeline.\n",
    "\n",
    "        >>> @LogResult(name=\"loss\")\n",
    "        >>> def loss(y_true, y_preds):\n",
    "        >>>     return 42\n",
    "        42\n",
    "\n",
    "        :param name: The name for the logged result.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, f: Callable) -> Callable:\n",
    "        def wrapped_f(*args, **kwargs):\n",
    "            result = f(*args, **kwargs)\n",
    "            log_value(name=self.name, value=result)\n",
    "            return result\n",
    "\n",
    "        return wrapped_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LogCall(object):\n",
    "    def __init__(self, *, name: str) -> None:\n",
    "        \"\"\"\n",
    "        Annotation to log the number of times a function is called.\n",
    "\n",
    "        The following example logs a variable step, which tracks how often the function step gets called.\n",
    "\n",
    "        >>> @LogCall(name=\"step\")\n",
    "        >>> def step():\n",
    "        >>>     # Fancy training code...\n",
    "        >>>     return 42\n",
    "        42\n",
    "\n",
    "        :param name: The name of the logged function call counting.\n",
    "        :param primary: If the logged result is the primary loss (it probably isn't)\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.i = 0\n",
    "\n",
    "    def __call__(self, f: Callable) -> Callable:\n",
    "        def wrapped_f(*args, **kwargs):\n",
    "            log_value(name=self.name, value=self.i)\n",
    "            self.i += 1\n",
    "            result = f(*args, **kwargs)\n",
    "            return result\n",
    "\n",
    "        return wrapped_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

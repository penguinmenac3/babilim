{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# babilim.core.logger\n",
    "\n",
    "> Logging for tensorflow and pytorch.\n",
    "\n",
    "This code is under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2019 Michael Fuerst\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "import datetime\n",
    "import filecmp\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from typing import Callable, List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import entangle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from babilim.core.config import Config\n",
    "from babilim import info, warn, DEBUG_VERBOSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "__log_file = None\n",
    "__checkpoint_path = None\n",
    "__last_progress = 0\n",
    "__last_update = time.time()\n",
    "__entanglement = None\n",
    "\n",
    "PYTHON_IGNORE_LIST = [\"__pycache__\", \"*.pyc\", \".ipynb_checkpoints\", \"checkpoints\", \"dist\", \"docs\", \"*.egg-info\",\n",
    "                      \"tfrecords\", \"*.code-workspace\", \".git\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _ignore(candidate: str, forbidden_list: List[str]) -> bool:\n",
    "    # Parse list to find simple placeholder notations\n",
    "    start_list = []\n",
    "    end_list = []\n",
    "    for item in forbidden_list:\n",
    "        if item.startswith(\"*\"):\n",
    "            end_list.append(item.replace(\"*\", \"\"))\n",
    "        if item.endswith(\"*\"):\n",
    "            start_list.append(item.replace(\"*\", \"\"))\n",
    "    # Test\n",
    "    res = candidate in forbidden_list\n",
    "    for item in start_list:\n",
    "        res |= candidate.startswith(item)\n",
    "    for item in end_list:\n",
    "        res |= candidate.endswith(item)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def __get_all_files(root: str, forbidden_list: List[str]) -> List[str]:\n",
    "    all_files = []\n",
    "    root_with_sep = root + os.sep\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        files = [x for x in files if not _ignore(x, forbidden_list)]\n",
    "        subdirs[:] = [x for x in subdirs if not x.startswith(\".\") and not _ignore(x, forbidden_list)]\n",
    "        for name in files:\n",
    "            all_files.append(os.path.join(path, name).replace(root_with_sep, \"\"))\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_loaded_files(root: str = None, forbidden_list: List[str] = PYTHON_IGNORE_LIST) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get a list of all files that correspond to loaded modules in the root folder.\n",
    "\n",
    "    If root is None the current cwd is used.\n",
    "    \"\"\"\n",
    "    if root is None:\n",
    "        root = os.getcwd()\n",
    "\n",
    "    cwd_files = __get_all_files(root, forbidden_list)\n",
    "    # TODO filter out all files that are not loaded.\n",
    "\n",
    "    return cwd_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_backup_path(fname: str, outp_dir: str = None) -> str:\n",
    "    assert outp_dir is not None\n",
    "\n",
    "    return os.path.join(os.path.normpath(outp_dir), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _copyfile(src: str, dst: str, follow_symlinks: bool = True, create_missing_dirs: bool = True) -> None:\n",
    "    dst_dir = os.path.dirname(dst)\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "\n",
    "    shutil.copyfile(src, dst, follow_symlinks=follow_symlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _write_log(*, obj: object) -> None:\n",
    "    \"\"\"\n",
    "    Write a log to the logfile or console if none is available.\n",
    "    Furthermore send it to the online server if it is connected.\n",
    "\n",
    "    :param obj: The json serializable object to log.\n",
    "    \"\"\"\n",
    "    global __log_file\n",
    "    global __entanglement\n",
    "    out_str = json.dumps(obj)\n",
    "    if __log_file is None:\n",
    "        warn(\"You should setup logger before using it. Call ailab.logger.setup(...).\")\n",
    "        warn(out_str)\n",
    "    else:\n",
    "        with open(__log_file, \"a\") as f:\n",
    "            f.write(out_str + \"\\n\")\n",
    "\n",
    "    if __entanglement is not None:\n",
    "        # TODO send to server\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def log_value(*, name: str, value: object, primary: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Log a value to the file or online server.\n",
    "    :param name: The name of the value to be logged.\n",
    "    :param value: The actual value. It can be anything that is json serializable.\n",
    "    :param primary: When primary is true this is the metric that is displayed online in the results preview.\n",
    "    It should be only true for the main loss.\n",
    "    \"\"\"\n",
    "    date = {\n",
    "        \"timestamp\": \"{}\".format(datetime.datetime.now()),\n",
    "        \"name\": name,\n",
    "        \"value\": value,\n",
    "        \"primary\": primary\n",
    "    }\n",
    "    _write_log(obj=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_progress(progress: float) -> None:\n",
    "    \"\"\"\n",
    "    Update the progress value. Automatically also computes the ETA and updates it in the logs.\n",
    "    :param progress: A value between 0 and 1 indicating the progress, where 1 means done.\n",
    "    The value should grow monotonic.\n",
    "    \"\"\"\n",
    "    global __last_progress\n",
    "    global __last_update\n",
    "\n",
    "    assert 0 <= progress <= 1\n",
    "\n",
    "    delta_t = time.time() - __last_update\n",
    "    delta_p = max(progress - __last_progress, 1E-6)\n",
    "    __last_update = time.time()\n",
    "    __last_progress = progress\n",
    "    eta = (1 - progress) / delta_p * delta_t\n",
    "\n",
    "    date = {\n",
    "        \"timestamp\": \"{}\".format(datetime.datetime.now()),\n",
    "        \"eta\": int(eta),\n",
    "        \"progress\": int(progress * 1000) / 1000\n",
    "    }\n",
    "    _write_log(obj=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _log_code(*, chkpt_path: str, forbidden_list: list = []) -> None:\n",
    "    \"\"\"\n",
    "    Log the code of the current working directory into the src folder of your checkpoint path.\n",
    "\n",
    "    :param chkpt_path: The checkpoint folder.\n",
    "    :param forbidden_list: The list of the forbidden files.\n",
    "    \"\"\"\n",
    "    outp_dir = os.path.join(chkpt_path, \"src\")\n",
    "    forbidden_list.extend(PYTHON_IGNORE_LIST)\n",
    "\n",
    "    loaded_files = _get_loaded_files(forbidden_list=forbidden_list)\n",
    "    # Copy preparation code to output location and load the module.\n",
    "    for f in loaded_files:\n",
    "        f_backup = _get_backup_path(f, outp_dir=outp_dir)\n",
    "        _copyfile(f, f_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _is_code_log_up_to_date(*, chkpt_path: str, forbidden_list: list = []) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the code in the logs is up to date or needs updates.\n",
    "\n",
    "    :param chkpt_path: The checkpoint folder.\n",
    "    :param forbidden_list: The list of the forbidden files.\n",
    "    :return: True if the files are up to date, False if not.\n",
    "    \"\"\"\n",
    "    outp_dir = os.path.join(chkpt_path, \"src\")\n",
    "    if not os.path.exists(outp_dir):\n",
    "        return False\n",
    "    forbidden_list.extend(PYTHON_IGNORE_LIST)\n",
    "    loaded_files = _get_loaded_files(forbidden_list=forbidden_list)\n",
    "\n",
    "    for f in loaded_files:\n",
    "        f_backup = _get_backup_path(f, outp_dir=outp_dir)\n",
    "        # Check if data is already up to date\n",
    "        if not os.path.exists(f_backup) or not filecmp.cmp(f, f_backup):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def log_image(*, name: str, data: np.ndarray = None) -> None:\n",
    "    \"\"\"\n",
    "    Log an image.\n",
    "    :param name: The name of the image.\n",
    "    :param data: The data (optional) if none is provided it is assumed that a pyplot figure should be saved.\n",
    "    \"\"\"\n",
    "    global __checkpoint_path\n",
    "    if __checkpoint_path is None:\n",
    "        warn(\"Cannot log images when logger is not setup. Call logger.setup first\")\n",
    "        return\n",
    "    if data is None:\n",
    "        plt.savefig(os.path.join(__checkpoint_path, \"images\", name + \".png\"))\n",
    "    else:\n",
    "        scipy.misc.imsave(os.path.join(__checkpoint_path, \"images\", name + \".png\"), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def setup(config: Config, continue_with_specific_checkpointpath: bool = False, continue_training: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Setup the logger.\n",
    "    This creates the folder structure required at the place specified in config.train.checkpoint_path.\n",
    "    After creating the folder structure it backs up the code of the current working directory to the folder structure.\n",
    "\n",
    "    :param config: The configuration that is used for this run.\n",
    "    :param continue_with_specific_checkpointpath: When a specific checkpoint is used to continue a run, set this. This avoids creating a new folder if it is not required.\n",
    "    :param continue_training: Same as specific checkpoint but the checkpoint is automatically selected to be the most recent. This avoids creating a new folder if it is not required.\n",
    "    :return: The path to the checkpoint folder.\n",
    "    \"\"\"\n",
    "    global __log_file\n",
    "    global __checkpoint_path\n",
    "    if __log_file is not None:\n",
    "        raise RuntimeError(\"You must not setup logger twice!\")\n",
    "    time_stamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d_%H.%M.%S')\n",
    "    chkpt_path = config.train_checkpoint_path + \"/\" + time_stamp\n",
    "    chkpt_path = chkpt_path + \"_\" + config.train_experiment_name\n",
    "\n",
    "    if continue_with_specific_checkpointpath:\n",
    "        chkpt_path = config.train_checkpoint_path + \"/\" + continue_with_specific_checkpointpath\n",
    "        if DEBUG_VERBOSITY:\n",
    "            info(\"Continue with checkpoint: {}\".format(chkpt_path))\n",
    "    elif continue_training:\n",
    "        chkpts = sorted([name for name in os.listdir(config.train_checkpoint_path)])\n",
    "        chkpt_path = config.train_checkpoint_path + \"/\" + chkpts[-1]\n",
    "        if DEBUG_VERBOSITY:\n",
    "            info(\"Latest found checkpoint: {}\".format(chkpt_path))\n",
    "\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"train\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"train\"))\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"val\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"val\"))\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"checkpoints\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"checkpoints\"))\n",
    "    if not os.path.exists(os.path.join(chkpt_path, \"images\")):\n",
    "        os.makedirs(os.path.join(chkpt_path, \"images\"))\n",
    "\n",
    "    if not _is_code_log_up_to_date(chkpt_path=chkpt_path):\n",
    "        _log_code(chkpt_path=chkpt_path)\n",
    "    __log_file = os.path.join(chkpt_path, \"log.txt\")\n",
    "    __checkpoint_path = chkpt_path\n",
    "    config.train_actual_checkpoint_path = chkpt_path\n",
    "    return chkpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def connect_ailab(*, host: str, port: int, user: str, password: str) -> bool:\n",
    "    \"\"\"\n",
    "    Connect to an ailab server for live logger of the experiment.\n",
    "\n",
    "    :param host: Hostname of the server.\n",
    "    :param port: The port on which ailab-server runs.\n",
    "    :param user: Your username to authenticate in ailab.\n",
    "    :param password: Your password to authenticate in ailab.\n",
    "    :return: True if the connection was established False otherwise.\n",
    "    \"\"\"\n",
    "    global __entanglement\n",
    "    if __entanglement is not None:\n",
    "        raise RuntimeError(\"You must not connect to a server for live logger twice!\")\n",
    "    __entanglement = entangle.connect(host=host, port=port, user=user, password=password)\n",
    "    if __entanglement is None:\n",
    "        return False\n",
    "\n",
    "    def on_close():\n",
    "        global __entanglement\n",
    "        __entanglement = None\n",
    "    __entanglement.on_close = on_close\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LogResult(object):\n",
    "    def __init__(self, *, name: str, primary: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Annotation to log the result of a function.\n",
    "\n",
    "        A simple example would be the primary loss the training pipeline.\n",
    "\n",
    "        >>> @LogResult(name=\"loss\", primary=True)\n",
    "        >>> def loss(y_true, y_preds):\n",
    "        >>>     return 42\n",
    "        42\n",
    "\n",
    "        :param name: The name for the logged result.\n",
    "        :param primary: If the result is the primary loss.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.primary = primary\n",
    "\n",
    "    def __call__(self, f: Callable) -> Callable:\n",
    "        def wrapped_f(*args, **kwargs):\n",
    "            result = f(*args, **kwargs)\n",
    "            log_value(name=self.name, value=result, primary=self.primary)\n",
    "            return result\n",
    "\n",
    "        return wrapped_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LogCall(object):\n",
    "    def __init__(self, *, name: str, primary: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Annotation to log the number of times a function is called.\n",
    "\n",
    "        The following example logs a variable step, which tracks how often the function step gets called.\n",
    "\n",
    "        >>> @LogCall(name=\"step\")\n",
    "        >>> def step():\n",
    "        >>>     # Fancy training code...\n",
    "        >>>     return 42\n",
    "        42\n",
    "\n",
    "        :param name: The name of the logged function call counting.\n",
    "        :param primary: If the logged result is the primary loss (it probably isn't)\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.primary = primary\n",
    "        self.i = 0\n",
    "\n",
    "    def __call__(self, f: Callable) -> Callable:\n",
    "        def wrapped_f(*args, **kwargs):\n",
    "            log_value(name=self.name, value=self.i, primary=self.primary)\n",
    "            self.i += 1\n",
    "            result = f(*args, **kwargs)\n",
    "            return result\n",
    "\n",
    "        return wrapped_f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}



<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Losses &amp; Metrics &mdash; babilim 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Models" href="babilim.models.html" />
    <link rel="prev" title="Logging &amp; Checkpoints" href="babilim.logger.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> babilim
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials.install.html">Install Babilim</a></li>
</ul>
<p class="caption"><span class="caption-text">Packages</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="babilim.html">Main Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.callbacks.html">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.core.html">Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.experiment.html">Experiment Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.logger.html">Logging &amp; Checkpoints</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Losses &amp; Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.optimizers.html">Optimizers &amp; Learning Rates</a></li>
<li class="toctree-l1"><a class="reference internal" href="babilim.utils.html">Utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="examples.mnist.html">MNIST Example (Babilim)</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.mnist.pytorch.html">MNIST Example (Pytorch Native)</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">babilim</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Losses &amp; Metrics</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/babilim.losses.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="losses-metrics">
<h1>Losses &amp; Metrics<a class="headerlink" href="#losses-metrics" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Loss</strong></p>
<p>The loss ties your network output and the dataset labels together.
It is a function that expects two inputs, one for the network outputs y_pred and one for the dataset labels y_true.</p>
<p>There are pre implemented loss functions which work on tensors, but for your problem you will need to define your own custom loss.
However, your custom loss can internally use existing losses.
This is because the network output and dataset output is typed and generic losses do not have those types.
The reason behind that is simply a level of type safety for you.</p>
<p>The simple example below shows how a classification loss could look for your problem:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">babilim.core</span> <span class="kn">import</span> <span class="n">ITensor</span>
<span class="kn">from</span> <span class="nn">babilim.losses</span> <span class="kn">import</span> <span class="n">Loss</span><span class="p">,</span> <span class="n">SparseCrossEntropyLossFromLogits</span>

<span class="k">class</span> <span class="nc">MyLoss</span><span class="p">(</span><span class="n">Loss</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">SparseCrossEntropyLossFromLogits</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">NetworkOutput</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">NetworkOutput</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ITensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">class_id</span><span class="p">,</span> <span class="n">y_true</span><span class="o">.</span><span class="n">class_id</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Metrics</strong></p>
<p>Metrics are similar to a loss, however, they do not return any tensor for optimization and have the sole purpose of giving you insight in your network.</p>
<p>A simple example could be the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">babilim.losses</span> <span class="kn">import</span> <span class="n">Metrics</span><span class="p">,</span> <span class="n">SparseCrossEntropyLossFromLogits</span><span class="p">,</span> <span class="n">SparseCategoricalAccuracy</span>

<span class="k">class</span> <span class="nc">FashionMnistMetrics</span><span class="p">(</span><span class="n">Metrics</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce</span> <span class="o">=</span> <span class="n">SparseCrossEntropyLossFromLogits</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ca</span> <span class="o">=</span> <span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">NetworkOutput</span><span class="p">,</span> <span class="n">y_true</span><span class="p">:</span> <span class="n">NetworkOutput</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;ce&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">class_id</span><span class="p">,</span> <span class="n">y_true</span><span class="o">.</span><span class="n">class_id</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;ca&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca</span><span class="p">(</span><span class="n">y_pred</span><span class="o">.</span><span class="n">class_id</span><span class="p">,</span> <span class="n">y_true</span><span class="o">.</span><span class="n">class_id</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<p><strong>Autogenerated Documentation</strong></p>
<span class="target" id="module-babilim.losses"></span><dl class="class">
<dt id="babilim.losses.Metrics">
<em class="property">class </em><code class="sig-prename descclassname">babilim.losses.</code><code class="sig-name descname">Metrics</code><a class="headerlink" href="#babilim.losses.Metrics" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">babilim.core.statefull_object.StatefullObject</span></code></p>
<dl class="method">
<dt id="babilim.losses.Metrics.avg">
<em class="property">property </em><code class="sig-name descname">avg</code><a class="headerlink" href="#babilim.losses.Metrics.avg" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="babilim.losses.Metrics.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">y_pred: Any</em>, <em class="sig-param">y_true: Any</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#babilim.losses.Metrics.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement a couple of metrics function between preds and true outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> â The predictions of the network. Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
<li><p><strong>y_true</strong> â The desired outputs of the network (labels). Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="babilim.losses.Metrics.log">
<code class="sig-name descname">log</code><span class="sig-paren">(</span><em class="sig-param">name: str</em>, <em class="sig-param">value: babilim.core.itensor.ITensor</em><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.Metrics.log" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="babilim.losses.Metrics.reset_avg">
<code class="sig-name descname">reset_avg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.Metrics.reset_avg" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="babilim.losses.Metrics.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">samples_seen</em>, <em class="sig-param">summary_writer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.Metrics.summary" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="babilim.losses.Loss">
<em class="property">class </em><code class="sig-prename descclassname">babilim.losses.</code><code class="sig-name descname">Loss</code><a class="headerlink" href="#babilim.losses.Loss" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">babilim.core.statefull_object.StatefullObject</span></code></p>
<dl class="method">
<dt id="babilim.losses.Loss.avg">
<em class="property">property </em><code class="sig-name descname">avg</code><a class="headerlink" href="#babilim.losses.Loss.avg" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="babilim.losses.Loss.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">y_pred: Any</em>, <em class="sig-param">y_true: Any</em><span class="sig-paren">)</span> &#x2192; babilim.core.itensor.ITensor<a class="headerlink" href="#babilim.losses.Loss.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement a loss function between preds and true outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> â The predictions of the network. Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
<li><p><strong>y_true</strong> â The desired outputs of the network (labels). Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="babilim.losses.Loss.log">
<code class="sig-name descname">log</code><span class="sig-paren">(</span><em class="sig-param">name: str</em>, <em class="sig-param">value: babilim.core.itensor.ITensor</em><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.Loss.log" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="babilim.losses.Loss.reset_avg">
<code class="sig-name descname">reset_avg</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.Loss.reset_avg" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="babilim.losses.Loss.summary">
<code class="sig-name descname">summary</code><span class="sig-paren">(</span><em class="sig-param">samples_seen</em>, <em class="sig-param">summary_writer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.Loss.summary" title="Permalink to this definition">Â¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="babilim.losses.NativeLossWrapper">
<em class="property">class </em><code class="sig-prename descclassname">babilim.losses.</code><code class="sig-name descname">NativeLossWrapper</code><span class="sig-paren">(</span><em class="sig-param">loss</em><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.NativeLossWrapper" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">babilim.losses.loss.Loss</span></code></p>
<dl class="method">
<dt id="babilim.losses.NativeLossWrapper.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">y_pred: Any</em>, <em class="sig-param">y_true: Any</em><span class="sig-paren">)</span> &#x2192; babilim.core.itensor.ITensor<a class="headerlink" href="#babilim.losses.NativeLossWrapper.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement a loss function between preds and true outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> â The predictions of the network. Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
<li><p><strong>y_true</strong> â The desired outputs of the network (labels). Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="babilim.losses.NativeMetricsWrapper">
<em class="property">class </em><code class="sig-prename descclassname">babilim.losses.</code><code class="sig-name descname">NativeMetricsWrapper</code><span class="sig-paren">(</span><em class="sig-param">metrics</em><span class="sig-paren">)</span><a class="headerlink" href="#babilim.losses.NativeMetricsWrapper" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">babilim.losses.metrics.Metrics</span></code></p>
<dl class="method">
<dt id="babilim.losses.NativeMetricsWrapper.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">y_pred: Any</em>, <em class="sig-param">y_true: Any</em><span class="sig-paren">)</span> &#x2192; None<a class="headerlink" href="#babilim.losses.NativeMetricsWrapper.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement a couple of metrics function between preds and true outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> â The predictions of the network. Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
<li><p><strong>y_true</strong> â The desired outputs of the network (labels). Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="babilim.losses.SparseCrossEntropyLossFromLogits">
<em class="property">class </em><code class="sig-prename descclassname">babilim.losses.</code><code class="sig-name descname">SparseCrossEntropyLossFromLogits</code><a class="headerlink" href="#babilim.losses.SparseCrossEntropyLossFromLogits" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">babilim.losses.loss.Loss</span></code></p>
<dl class="method">
<dt id="babilim.losses.SparseCrossEntropyLossFromLogits.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">y_pred: babilim.core.itensor.ITensor</em>, <em class="sig-param">y_true: babilim.core.itensor.ITensor</em><span class="sig-paren">)</span> &#x2192; babilim.core.itensor.ITensor<a class="headerlink" href="#babilim.losses.SparseCrossEntropyLossFromLogits.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement a loss function between preds and true outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> â The predictions of the network. Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
<li><p><strong>y_true</strong> â The desired outputs of the network (labels). Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="babilim.losses.MeanSquaredError">
<em class="property">class </em><code class="sig-prename descclassname">babilim.losses.</code><code class="sig-name descname">MeanSquaredError</code><a class="headerlink" href="#babilim.losses.MeanSquaredError" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">babilim.losses.loss.Loss</span></code></p>
<dl class="method">
<dt id="babilim.losses.MeanSquaredError.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">y_pred: babilim.core.itensor.ITensor</em>, <em class="sig-param">y_true: babilim.core.itensor.ITensor</em>, <em class="sig-param">axis: int = -1</em><span class="sig-paren">)</span> &#x2192; babilim.core.itensor.ITensor<a class="headerlink" href="#babilim.losses.MeanSquaredError.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement a loss function between preds and true outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> â The predictions of the network. Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
<li><p><strong>y_true</strong> â The desired outputs of the network (labels). Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="babilim.losses.SparseCategoricalAccuracy">
<em class="property">class </em><code class="sig-prename descclassname">babilim.losses.</code><code class="sig-name descname">SparseCategoricalAccuracy</code><a class="headerlink" href="#babilim.losses.SparseCategoricalAccuracy" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">babilim.losses.loss.Loss</span></code></p>
<dl class="method">
<dt id="babilim.losses.SparseCategoricalAccuracy.call">
<code class="sig-name descname">call</code><span class="sig-paren">(</span><em class="sig-param">y_pred: babilim.core.itensor.ITensor</em>, <em class="sig-param">y_true: babilim.core.itensor.ITensor</em>, <em class="sig-param">axis: int = -1</em><span class="sig-paren">)</span> &#x2192; babilim.core.itensor.ITensor<a class="headerlink" href="#babilim.losses.SparseCategoricalAccuracy.call" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Implement a loss function between preds and true outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> â The predictions of the network. Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
<li><p><strong>y_true</strong> â The desired outputs of the network (labels). Either a NamedTuple pointing at ITensors or a Dict or Tuple of ITensors.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="babilim.models.html" class="btn btn-neutral float-right" title="Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="babilim.logger.html" class="btn btn-neutral float-left" title="Logging &amp; Checkpoints" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Michael Fuerst

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
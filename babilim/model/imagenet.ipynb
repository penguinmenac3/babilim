{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# babilim.model.imagenet\n",
    "\n",
    "> An implemntation of various imagenet models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from babilim.core.annotations import RunOnlyOnce\n",
    "from babilim.core.module_native import ModuleNative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImagenetModel(ModuleNative):\n",
    "    def __init__(self, encoder_type, only_encoder=False, pretrained=False):\n",
    "        \"\"\"\n",
    "        Create one of the iconic image net models in one line.\n",
    "        Allows for only using the encoder part.\n",
    "\n",
    "        This model assumes the input image to be 0-255 (8 bit integer) with 3 channels.\n",
    "\n",
    "        :param encoder_type: The encoder type that should be used. Must be in (\"vgg16\", \"vgg16_bn\", \"vgg19\", \"vgg19_bn\", \"resnet50\", \"resnet101\", \"resnet152\", \"densenet121\", \"densenet169\", \"densenet201\", \"inception_v3\", \"mobilenet_v2\")\n",
    "        :param only_encoder: Leaves out the classification head for VGG16 leaving you with a feature encoder.\n",
    "        :param pretrained: If you want imagenet weights for this network.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.only_encoder = only_encoder\n",
    "        self.pretrained = pretrained\n",
    "        self.encoder_type = encoder_type\n",
    "\n",
    "    @RunOnlyOnce\n",
    "    def _build_tf(self, image):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _call_tf(self, image):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @RunOnlyOnce\n",
    "    def _build_pytorch(self, image):\n",
    "        import torch\n",
    "        from torchvision.models import vgg16_bn, vgg16_bn, vgg19, vgg19_bn, resnet50, resnet101, resnet152, densenet121, densenet169, densenet201, inception_v3, mobilenet_v2\n",
    "        from torch.nn import Sequential\n",
    "        model = None\n",
    "        if self.encoder_type == \"vgg16\":\n",
    "            model = vgg16\n",
    "        elif self.encoder_type == \"vgg16_bn\":\n",
    "            model = vgg16_bn\n",
    "        elif self.encoder_type == \"vgg19\":\n",
    "            model = vgg19\n",
    "        elif self.encoder_type == \"vgg19_bn\":\n",
    "            model = vgg19_bn\n",
    "        elif self.encoder_type == \"resnet50\":\n",
    "            model = resnet50\n",
    "        elif self.encoder_type == \"resnet101\":\n",
    "            model = resnet101\n",
    "        elif self.encoder_type == \"resnet152\":\n",
    "            model = resnet152\n",
    "        elif self.encoder_type == \"densenet121\":\n",
    "            model = densenet121\n",
    "        elif self.encoder_type == \"densenet169\":\n",
    "            model = densenet169\n",
    "        elif self.encoder_type == \"densenet201\":\n",
    "            model = densenet201\n",
    "        elif self.encoder_type == \"inception_v3\":\n",
    "            model = inception_v3\n",
    "        elif self.encoder_type == \"mobilenet_v2\":\n",
    "            model = mobilenet_v2\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported encoder type.\")\n",
    "        \n",
    "        if self.only_encoder:\n",
    "            self.model = Sequential(*list(model(pretrained=self.pretrained).features))\n",
    "        else:\n",
    "            self.model = model(pretrained=self.pretrained)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.to(torch.device(self.device))\n",
    "        \n",
    "        # Just in case, make the image a float tensor\n",
    "        image = image.float()\n",
    "\n",
    "        # Standardization values from torchvision.models documentation\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        # Create tensors for a 0-255 value range image.\n",
    "        self.mean = torch.as_tensor([i * 255 for i in mean], dtype=image.dtype, device=image.device)\n",
    "        self.std = torch.as_tensor([j * 255 for j in std], dtype=image.dtype, device=image.device)\n",
    "\n",
    "    def _call_pytorch(self, image):\n",
    "        # Just in case, make the image a float tensor and apply variance correction.\n",
    "        image = image.float()\n",
    "        image.sub_(self.mean[None, :, None, None]).div_(self.std[None, :, None, None])\n",
    "\n",
    "        return self.model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 3, 256, 256)\n(1, 512, 8, 8)\n"
    }
   ],
   "source": [
    "from babilim.core.tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "encoder = ImagenetModel(\"vgg16_bn\", only_encoder=True, pretrained=\"imagenet\")\n",
    "fake_image_batch_pytorch = Tensor(data=np.zeros((1, 3, 256, 256), dtype=np.float32), trainable=False)\n",
    "print(fake_image_batch_pytorch.shape)\n",
    "result = encoder(fake_image_batch_pytorch)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 3, 256, 256)\nDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\fuerst/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 97.8M/97.8M [00:23<00:00, 4.41MB/s]\n(1, 1000)\n"
    }
   ],
   "source": [
    "from babilim.core.tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "model = ImagenetModel(\"resnet50\", only_encoder=False, pretrained=\"imagenet\")\n",
    "fake_image_batch_pytorch = Tensor(data=np.zeros((1, 3, 256, 256), dtype=np.float32), trainable=False)\n",
    "print(fake_image_batch_pytorch.shape)\n",
    "result = model(fake_image_batch_pytorch)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondae7cd72b7144542bdae788b1dbf27e222"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

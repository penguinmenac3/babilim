{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# babilim.model.layers.batch_normalization\n",
    "\n",
    "> Apply batch normalization to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from babilim.core.annotations import RunOnlyOnce\n",
    "from babilim.core.module_native import ModuleNative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchNormalization(ModuleNative):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        A batch normalization layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "    @RunOnlyOnce\n",
    "    def _build_pytorch(self, features):\n",
    "        import torch\n",
    "        from torch.nn import BatchNorm1d, BatchNorm2d, BatchNorm3d\n",
    "        if len(features.shape) == 2 or len(features.shape) == 3:\n",
    "            self.bn = BatchNorm1d(num_features=features.shape[1])\n",
    "        elif len(features.shape) == 4:\n",
    "            self.bn = BatchNorm2d(num_features=features.shape[1])\n",
    "        elif len(features.shape) == 5:\n",
    "            self.bn = BatchNorm3d(num_features=features.shape[1])\n",
    "        else:\n",
    "            raise RuntimeError(\"Batch norm not available for other input shapes than [B,L], [B,C,L], [B,C,H,W] or [B,C,D,H,W] dimensional.\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.bn = self.bn.to(torch.device(\"cuda\"))  # TODO move to correct device\n",
    "        \n",
    "    def _call_pytorch(self, features):\n",
    "        return self.bn(features)\n",
    "    \n",
    "    @RunOnlyOnce\n",
    "    def _build_tf(self, features):\n",
    "        from tensorflow.keras.layers import BatchNormalization as _BN\n",
    "        self.bn = _BN()\n",
    "        \n",
    "    def _call_tf(self, features):\n",
    "        return self.bn(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3, 4)\ntensor([[10.,  3., -4.,  2.],\n        [ 5.,  5.,  4., -2.],\n        [ 1., -7.,  2.,  0.]], device='cuda:0')\n(3, 4)\ntensor([[ 1.2675,  0.5080, -1.3728,  1.2247],\n        [-0.0905,  0.8890,  0.9806, -1.2247],\n        [-1.1770, -1.3970,  0.3922,  0.0000]], device='cuda:0',\n       grad_fn=<CudnnBatchNormBackward>)\n"
    }
   ],
   "source": [
    "from babilim.core.tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "batch_norm = BatchNormalization()\n",
    "tensor = Tensor(data=np.array([[10,3,-4,2], [5, 5, 4, -2], [1,-7,2,0]], dtype=np.float32), trainable=False)\n",
    "\n",
    "print(tensor.shape)\n",
    "print(tensor)\n",
    "result = batch_norm(tensor)\n",
    "print(tensor.shape)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondae7cd72b7144542bdae788b1dbf27e222"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

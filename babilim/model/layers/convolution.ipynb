{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# babilim.model.layers.convolution\n",
    "\n",
    "> Convolution for 1d and 2d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import Optional, Any, Tuple\n",
    "from babilim.core.annotations import RunOnlyOnce\n",
    "from babilim.core.module_native import ModuleNative\n",
    "from babilim.model.layers.activation import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Conv1D(ModuleNative):\n",
    "    def __init__(self, filters: int, kernel_size: int, padding: Optional[str] = None, stride: int = 1, dilation_rate: int = 1, kernel_initializer: Optional[Any] = None, activation=None):\n",
    "        \"\"\"\n",
    "        A 1d convolution layer.\n",
    "    \n",
    "        :param filters: The number of filters in the convolution. Defines the number of output channels.\n",
    "        :param kernel_size: The kernel size of the convolution. Defines the area over which is convolved. Typically 1, 3 or 5 are recommended.\n",
    "        :param padding: What type of padding should be applied. The string \"none\" means no padding is applied, None or \"same\" means the input is padded in a way that the output stays the same size if no stride is applied.\n",
    "        :param stride: The offset between two convolutions that are applied. Typically 1. Stride affects also the resolution of the output feature map. A stride 2 halves the resolution, since convolutions are only applied every odd pixel.\n",
    "        :param dilation_rate: The dilation rate for a convolution.\n",
    "        :param kernel_initializer: A kernel initializer function. By default orthonormal weight initialization is used.\n",
    "        :param activation: The activation function that should be added after the dense layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation_rate\n",
    "        self.stride = stride\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.activation = Activation(activation)\n",
    "        \n",
    "    @RunOnlyOnce\n",
    "    def _build_pytorch(self, features):\n",
    "        import torch\n",
    "        from torch.nn import Conv1d as _Conv1d\n",
    "        if self.kernel_initializer is None:\n",
    "            from torch.nn.init import orthogonal_\n",
    "            self.kernel_initializer = orthogonal_\n",
    "        if self.padding == \"same\" or self.padding is None:\n",
    "            self.padding = int((self.kernel_size - 1) / 2)\n",
    "        elif self.padding == \"none\":\n",
    "            self.padding = 0\n",
    "        else:\n",
    "            raise NotImplementedError(\"Padding {} is not implemented.\".format(padding))\n",
    "        in_channels = features.shape[1]\n",
    "        self.conv = _Conv1d(in_channels, self.filters, self.kernel_size, self.stride, self.padding, self.dilation)\n",
    "        self.conv.weight.data = self.kernel_initializer(self.conv.weight.data)\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv = self.conv.to(torch.device(\"cuda\"))  # TODO move to correct device\n",
    "        from babilim.core.tensor_pt import Tensor as _Tensor\n",
    "        self.weight = _Tensor(data=None, trainable=True, native=self.conv.weight)\n",
    "        self.bias = _Tensor(data=None, trainable=True, native=self.conv.bias)\n",
    "        \n",
    "    def _call_pytorch(self, features):\n",
    "        return self.activation(self.conv(features))\n",
    "    \n",
    "    @RunOnlyOnce\n",
    "    def _build_tf(self, features):\n",
    "        #TODO Implement\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def _call_tf(self, features):\n",
    "        #TODO Implement\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10, 20, 30)\n(10, 10, 30)\n"
    }
   ],
   "source": [
    "from babilim.core.tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "conv1d = Conv1D(filters=10, kernel_size=1)\n",
    "tensor = Tensor(data=np.zeros((10,20,30), dtype=np.float32), trainable=False)\n",
    "\n",
    "print(tensor.shape)\n",
    "result = conv1d(tensor)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Conv2D(ModuleNative):\n",
    "    def __init__(self, filters: int, kernel_size: Tuple[int, int], padding: Optional[str] = None, strides: Tuple[int, int] = (1, 1), dilation_rate: Tuple[int, int] = (1, 1), kernel_initializer: Optional[Any] = None, activation=None):\n",
    "        \"\"\"\n",
    "        A 2d convolution layer.\n",
    "    \n",
    "        :param filters: The number of filters in the convolution. Defines the number of output channels.\n",
    "        :param kernel_size: The kernel size of the convolution. Defines the area over which is convolved. Typically (1,1) (3,3) or (5,5) are recommended.\n",
    "        :param padding: What type of padding should be applied. The string \"none\" means no padding is applied, None or \"same\" means the input is padded in a way that the output stays the same size if no stride is applied.\n",
    "        :param stride: The offset between two convolutions that are applied. Typically (1, 1). Stride affects also the resolution of the output feature map. A stride 2 halves the resolution, since convolutions are only applied every odd pixel.\n",
    "        :param dilation_rate: The dilation rate for a convolution.\n",
    "        :param kernel_initializer: A kernel initializer function. By default orthonormal weight initialization is used.\n",
    "        :param activation: The activation function that should be added after the dense layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation_rate\n",
    "        self.stride = strides\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.activation = Activation(activation)\n",
    "        \n",
    "    @RunOnlyOnce\n",
    "    def _build_pytorch(self, features):\n",
    "        import torch\n",
    "        from torch.nn import Conv2d as _Conv2d\n",
    "        if self.kernel_initializer is None:\n",
    "            from torch.nn.init import orthogonal_\n",
    "            self.kernel_initializer = orthogonal_\n",
    "        if self.padding == \"same\" or self.padding is None:\n",
    "            px = int((self.kernel_size[0] - 1) / 2)\n",
    "            py = int((self.kernel_size[1] - 1) / 2)\n",
    "            self.padding = (px, py)\n",
    "        elif self.padding == \"none\":\n",
    "            self.padding = (0, 0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Padding {} is not implemented.\".format(padding))\n",
    "        in_channels = features.shape[1]\n",
    "        self.conv = _Conv2d(in_channels, self.filters, self.kernel_size, self.stride, self.padding, self.dilation)\n",
    "        self.conv.weight.data = self.kernel_initializer(self.conv.weight.data)\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv = self.conv.to(torch.device(\"cuda\"))  # TODO move to correct device\n",
    "        from babilim.core.tensor_pt import Tensor as _Tensor\n",
    "        self.weight = _Tensor(data=None, trainable=True, native=self.conv.weight)\n",
    "        self.bias = _Tensor(data=None, trainable=True, native=self.conv.bias)\n",
    "        \n",
    "    def _call_pytorch(self, features):\n",
    "        return self.activation(self.conv(features))\n",
    "    \n",
    "    @RunOnlyOnce\n",
    "    def _build_tf(self, features):\n",
    "        from tensorflow.keras.layers import Conv2D as _Conv2D\n",
    "        if self.kernel_initializer is None:\n",
    "            from tensorflow.keras.initializers import Orthogonal\n",
    "            self.kernel_initializer = Orthogonal()\n",
    "        if self.padding is None:\n",
    "            self.padding = \"same\"\n",
    "        self.conv = _Conv2D(filters=self.filters, kernel_size=self.kernel_size, strides=self.stride, dilation_rate=self.dilation_rate, padding=self.padding, activation=None, kernel_initializer=self.kernel_initializer)\n",
    "        self.conv.build(features.shape)\n",
    "        from babilim.core.tensor_tf import Tensor as _Tensor\n",
    "        self.weight = _Tensor(data=None, trainable=True, native=self.conv.kernel)\n",
    "        self.bias = _Tensor(data=None, trainable=True, native=self.conv.bias)\n",
    "\n",
    "    def _call_tf(self, features):\n",
    "        raise self.activation(self.conv(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10, 20, 5, 5)\n(10, 10, 5, 5)\n"
    }
   ],
   "source": [
    "from babilim.core.tensor import Tensor\n",
    "import numpy as np\n",
    "\n",
    "conv2d = Conv2D(filters=10, kernel_size=(1, 1))\n",
    "tensor = Tensor(data=np.zeros((10, 20, 5, 5), dtype=np.float32), trainable=False)\n",
    "\n",
    "print(tensor.shape)\n",
    "tensor = conv2d(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondae7cd72b7144542bdae788b1dbf27e222"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}